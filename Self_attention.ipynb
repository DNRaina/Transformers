{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : [[-1.39958713 -0.22305316 -0.24340208 -1.08990745  0.53553258 -1.07093933\n",
      "  -0.41055511  0.33091434]\n",
      " [ 0.93078362 -0.52747605  0.24937592 -0.24626193  0.00363866  0.88400743\n",
      "   0.07809847 -0.95373199]\n",
      " [-0.54746032 -0.25787686 -0.41933473  0.19818332 -0.38553762  0.35117474\n",
      "  -2.03025696 -0.88274714]\n",
      " [ 0.75824541 -1.17511898  1.04668314  0.29246406  0.21119868  1.19905575\n",
      "  -0.90625828  0.75579743]]\n",
      "K : [[ 2.12356025 -1.47895449  1.65817848 -0.83509451  0.4421548   0.17046466\n",
      "   1.02055706  1.41988004]\n",
      " [ 1.67720882  0.8355391  -0.85573374  0.3876888   0.97649418 -0.12519466\n",
      "   0.34522402 -1.04967098]\n",
      " [ 0.07225795  0.397058    1.22354147  2.46358776  1.43919241 -1.38963153\n",
      "   0.49021882 -0.08332518]\n",
      " [ 2.04920499  0.2789356   0.19126586  1.37597425  0.37469164  0.39046281\n",
      "  -0.64558209  0.65654841]]\n",
      "V:  [[ 0.1183661  -1.72408159 -0.13483841 -0.58797534  0.99422244 -0.69578208\n",
      "   0.10959783  2.20105546]\n",
      " [-0.00756153 -0.45394379 -0.61849731 -0.16377034  0.48347382 -0.15590695\n",
      "  -1.05508056  0.90651759]\n",
      " [ 0.28099552 -0.26275775 -0.66495412  1.14541033 -0.78543672  1.07162106\n",
      "  -0.26459835 -0.15066588]\n",
      " [ 0.40424365  0.64770088  2.17998622  0.1358282  -0.33818133 -0.18987932\n",
      "  -0.89386833 -1.35321033]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "L, d_k, d_v = 4, 8, 8\n",
    "q = np.random.randn(L, d_k)\n",
    "k = np.random.randn(L, d_k)\n",
    "v = np.random.randn(L ,d_v)\n",
    "\n",
    "print(\"Q :\", q)\n",
    "print(f\"K : {k}\")\n",
    "print(\"V: \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <mtext>self attention</mtext>\n",
    "  <mo>=</mo>\n",
    "  <mi>s</mi>\n",
    "  <mi>o</mi>\n",
    "  <mi>f</mi>\n",
    "  <mi>t</mi>\n",
    "  <mi>m</mi>\n",
    "  <mi>a</mi>\n",
    "  <mi>x</mi>\n",
    "  <mrow data-mjx-texclass=\"ORD\">\n",
    "    <mo minsize=\"2.047em\" maxsize=\"2.047em\">(</mo>\n",
    "  </mrow>\n",
    "  <mfrac>\n",
    "    <mrow>\n",
    "      <mi>Q</mi>\n",
    "      <mo>.</mo>\n",
    "      <msup>\n",
    "        <mi>K</mi>\n",
    "        <mi>T</mi>\n",
    "      </msup>\n",
    "    </mrow>\n",
    "    <msqrt>\n",
    "      <msub>\n",
    "        <mi>d</mi>\n",
    "        <mi>k</mi>\n",
    "      </msub>\n",
    "    </msqrt>\n",
    "  </mfrac>\n",
    "  <mo>+</mo>\n",
    "  <mi>M</mi>\n",
    "  <mrow data-mjx-texclass=\"ORD\">\n",
    "    <mo minsize=\"2.047em\" maxsize=\"2.047em\">)</mo>\n",
    "  </mrow>\n",
    "</math>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <mtext>new V</mtext>\n",
    "  <mo>=</mo>\n",
    "  <mtext>self attention</mtext>\n",
    "  <mo>.</mo>\n",
    "  <mi>V</mi>\n",
    "</math>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.03055573, -2.5800914 , -1.14248138, -4.21169159],\n",
       "       [ 2.25366976,  1.73246562, -1.54920081,  1.13902682],\n",
       "       [-5.07800302, -0.89273901, -2.13136327, -0.27750446],\n",
       "       [ 5.28551216, -1.54250085, -0.28016198,  3.45723831]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q, k.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5917010369907185, 0.9793615634282073, 6.956340053105443)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var(), k.var(), np.matmul(q, k.T).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8695425066381802\n",
      "[[-0.71790986 -0.91220006 -0.40392817 -1.48905784]\n",
      " [ 0.79679258  0.61251909 -0.5477252   0.40270679]\n",
      " [-1.79534518 -0.31563091 -0.75355071 -0.09811264]\n",
      " [ 1.86871075 -0.54535641 -0.09905222  1.22231833]]\n"
     ]
    }
   ],
   "source": [
    "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "print(scaled.var()) #the variance for this is significantly smaller\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Masking\n",
    "\n",
    "    This is to ensure words don't get context from words generated in the future.\n",
    "    Not required in the encoders, but required in  the decoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones( (L, L)))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.71790986,        -inf,        -inf,        -inf],\n",
       "       [ 0.79679258,  0.61251909,        -inf,        -inf],\n",
       "       [-1.79534518, -0.31563091, -0.75355071,        -inf],\n",
       "       [ 1.86871075, -0.54535641, -0.09905222,  1.22231833]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <mtext>softmax</mtext>\n",
    "  <mo>=</mo>\n",
    "  <mfrac>\n",
    "    <msup>\n",
    "      <mi>e</mi>\n",
    "      <mrow data-mjx-texclass=\"ORD\">\n",
    "        <msub>\n",
    "          <mi>x</mi>\n",
    "          <mi>i</mi>\n",
    "        </msub>\n",
    "      </mrow>\n",
    "    </msup>\n",
    "    <mrow>\n",
    "      <munder>\n",
    "        <mo data-mjx-texclass=\"OP\">&#x2211;</mo>\n",
    "        <mi>j</mi>\n",
    "      </munder>\n",
    "      <msubsup>\n",
    "        <mi>e</mi>\n",
    "        <mi>j</mi>\n",
    "        <mi>x</mi>\n",
    "      </msubsup>\n",
    "    </mrow>\n",
    "  </mfrac>\n",
    "</math>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis = -1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.54593845, 0.45406155, 0.        , 0.        ],\n",
       "       [0.12156593, 0.53387995, 0.34455413, 0.        ],\n",
       "       [0.57040106, 0.0510228 , 0.07972449, 0.29885165]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = softmax(scaled+mask)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1183661 , -1.72408159, -0.13483841, -0.58797534,  0.99422244,\n",
       "        -0.69578208,  0.10959783,  2.20105546],\n",
       "       [ 0.06118721, -1.14736086, -0.35444932, -0.39536016,  0.76231113,\n",
       "        -0.45064554, -0.41923784,  1.61325559],\n",
       "       [ 0.1071705 , -0.54247533, -0.57570776,  0.23574439,  0.10835509,\n",
       "         0.20141247, -0.64113145,  0.69963236],\n",
       "       [ 0.21034145, -0.8339612 ,  0.49000993, -0.21182805,  0.42808913,\n",
       "        -0.37614096, -0.27954744,  0.88531653]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = np.matmul(attention, v)\n",
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1183661 , -1.72408159, -0.13483841, -0.58797534,  0.99422244,\n",
       "        -0.69578208,  0.10959783,  2.20105546],\n",
       "       [-0.00756153, -0.45394379, -0.61849731, -0.16377034,  0.48347382,\n",
       "        -0.15590695, -1.05508056,  0.90651759],\n",
       "       [ 0.28099552, -0.26275775, -0.66495412,  1.14541033, -0.78543672,\n",
       "         1.07162106, -0.26459835, -0.15066588],\n",
       "       [ 0.40424365,  0.64770088,  2.17998622,  0.1358282 , -0.33818133,\n",
       "        -0.18987932, -0.89386833, -1.35321033]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sclaed_dot_product_attention(q, k, v , mask = None):\n",
    "    d_k = q.shape[-1]\n",
    "    scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "\n",
    "    if mask.any():\n",
    "        scaled += mask\n",
    "    \n",
    "    attention = softmax(scaled)\n",
    "    out = np.matmul(attention, v)\n",
    "    return out,attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[-1.39958713 -0.22305316 -0.24340208 -1.08990745  0.53553258 -1.07093933\n",
      "  -0.41055511  0.33091434]\n",
      " [ 0.93078362 -0.52747605  0.24937592 -0.24626193  0.00363866  0.88400743\n",
      "   0.07809847 -0.95373199]\n",
      " [-0.54746032 -0.25787686 -0.41933473  0.19818332 -0.38553762  0.35117474\n",
      "  -2.03025696 -0.88274714]\n",
      " [ 0.75824541 -1.17511898  1.04668314  0.29246406  0.21119868  1.19905575\n",
      "  -0.90625828  0.75579743]]\n",
      "K\n",
      " [[ 2.12356025 -1.47895449  1.65817848 -0.83509451  0.4421548   0.17046466\n",
      "   1.02055706  1.41988004]\n",
      " [ 1.67720882  0.8355391  -0.85573374  0.3876888   0.97649418 -0.12519466\n",
      "   0.34522402 -1.04967098]\n",
      " [ 0.07225795  0.397058    1.22354147  2.46358776  1.43919241 -1.38963153\n",
      "   0.49021882 -0.08332518]\n",
      " [ 2.04920499  0.2789356   0.19126586  1.37597425  0.37469164  0.39046281\n",
      "  -0.64558209  0.65654841]]\n",
      "V\n",
      " [[ 0.1183661  -1.72408159 -0.13483841 -0.58797534  0.99422244 -0.69578208\n",
      "   0.10959783  2.20105546]\n",
      " [-0.00756153 -0.45394379 -0.61849731 -0.16377034  0.48347382 -0.15590695\n",
      "  -1.05508056  0.90651759]\n",
      " [ 0.28099552 -0.26275775 -0.66495412  1.14541033 -0.78543672  1.07162106\n",
      "  -0.26459835 -0.15066588]\n",
      " [ 0.40424365  0.64770088  2.17998622  0.1358282  -0.33818133 -0.18987932\n",
      "  -0.89386833 -1.35321033]]\n",
      "New V\n",
      " [[ 0.1183661  -1.72408159 -0.13483841 -0.58797534  0.99422244 -0.69578208\n",
      "   0.10959783  2.20105546]\n",
      " [ 0.06118721 -1.14736086 -0.35444932 -0.39536016  0.76231113 -0.45064554\n",
      "  -0.41923784  1.61325559]\n",
      " [ 0.1071705  -0.54247533 -0.57570776  0.23574439  0.10835509  0.20141247\n",
      "  -0.64113145  0.69963236]\n",
      " [ 0.21034145 -0.8339612   0.49000993 -0.21182805  0.42808913 -0.37614096\n",
      "  -0.27954744  0.88531653]]\n",
      "Attention\n",
      " [[1.         0.         0.         0.        ]\n",
      " [0.54593845 0.45406155 0.         0.        ]\n",
      " [0.12156593 0.53387995 0.34455413 0.        ]\n",
      " [0.57040106 0.0510228  0.07972449 0.29885165]]\n"
     ]
    }
   ],
   "source": [
    "values, attention = sclaed_dot_product_attention(q, k, v, mask = mask)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
